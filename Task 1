1. Short Answer Questions
Q1: Define algorithmic bias and provide two examples of how it manifests in AI systems.

Algorithmic bias refers to systematic and repeatable errors or unfair outcomes in AI systems that lead to discrimination against certain groups of people. These biases typically arise from issues in the data used to train the AI, the design of the algorithm itself, or the way the AI is deployed and used.


Examples of how it manifests in AI systems:

Biased Hiring Tools: An AI-powered recruiting tool, trained on historical hiring data, might inadvertently learn and perpetuate existing gender or racial biases. For instance, if past successful applicants for technical roles were predominantly male, the AI might downgrade resumes containing keywords associated with female candidates (e.g., "women's chess club") or show a preference for male-coded language, leading to fewer female candidates being shortlisted.


Facial Recognition Systems: These systems can exhibit algorithmic bias in their accuracy across different demographic groups. Studies have shown that some facial recognition technologies have significantly higher error rates when identifying individuals with darker skin tones, women, and non-binary individuals compared to lighter-skinned males. This can lead to wrongful arrests, increased surveillance of minority communities, and unequal access to services.



Q2: Explain the difference between transparency and explainability in AI. Why are both important?

Transparency in AI refers to the degree to which an AI system's inner workings, data, and decision-making processes are open and understandable to scrutiny. It's about revealing what the AI is doing and what data it uses. A transparent system allows stakeholders to see the rules, logic, and data sources that govern its behavior.


Explainability in AI (Explainable AI - XAI) refers to the ability to articulate why an AI system made a particular decision or prediction in a way that is comprehensible to humans. It's about understanding the reasoning behind the AI's output, especially for complex "black box" models like deep neural networks.

Why both are important:

Transparency is crucial for building trust in AI systems. If users, regulators, or the public can see how an AI operates, they are more likely to trust its outputs and accept its deployment. It also allows for auditing and identifying potential biases or vulnerabilities in the system's design or data.

Explainability is vital for accountability, fairness, and continuous improvement. When an AI makes a critical decision (e.g., denying a loan, diagnosing a disease), understanding the "why" allows humans to challenge incorrect decisions, identify and mitigate biases, comply with regulations (like GDPR's "right to explanation"), and refine the AI model over time to improve its performance and ethical alignment. Together, transparency and explainability empower stakeholders to govern AI effectively.

Q3: How does GDPR (General Data Protection Regulation) impact AI development in the EU?

The GDPR significantly impacts AI development within the European Union (EU) and for any AI system processing the personal data of EU citizens, regardless of where the development takes place. Key impacts include:

Lawful Basis for Processing: AI developers must establish a lawful basis (e.g., consent, legitimate interest, contractual necessity) for collecting and processing personal data. This often requires clear consent mechanisms for data used in AI training and deployment.

Data Minimization: AI systems should only collect and process personal data that is strictly necessary for their stated purpose, limiting the amount of sensitive data used in training models.

Data Subject Rights: GDPR grants individuals rights such as the "right to access" their data, the "right to rectification" (correct inaccuracies), the "right to erasure" (right to be forgotten), and importantly for AI, the "right to explanation" for decisions made solely based on automated processing, including profiling. This directly pushes for greater AI explainability.

Privacy by Design and Default: AI systems must be developed with privacy considerations embedded from the outset (by design) and default settings should be the most privacy-friendly. This impacts how data is collected, stored, and processed throughout the AI lifecycle.

Data Protection Impact Assessments (DPIAs): For high-risk AI systems that involve extensive processing of personal data, especially sensitive data or automated decision-making, developers are often required to conduct DPIAs to identify and mitigate privacy risks.

Accountability: GDPR emphasizes accountability, meaning organizations must be able to demonstrate compliance with its principles. This requires robust documentation of data processing activities, including those related to AI model training and deployment.


2. Ethical Principles Matching
B) Non-maleficence: Ensuring AI does not harm individuals or society.

C) Autonomy: Respecting usersâ€™ right to control their data and decisions.

D) Sustainability: Designing AI to be environmentally friendly.

A) Justice: Fair distribution of AI benefits and risks.
